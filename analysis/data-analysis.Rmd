---
title: "Dehumanization Project Data Analysis"
output: html_notebook
---

The R Version used to create this file is: `R version 4.3.2 (2023-10-31)`. 
To reproduce analysis, switch with your own version of R by pressing `Tools` > `Global Options` > `R Version`

Goal of the logistical regression: We would like to determine whether the agents expressing dehumanizing 
reactions are selected more frequently than those expressing non-dehumanizing reactions.


### Installing and downloading packages and preparing for analysis
```{r Download packages and format csv to prepare for analysis}

knitr::opts_knit$set(root.dir = '/Users/elizabethmiclau/Downloads/Dehumanization Project')

# Change out the working directory for your own

install.packages("remotes")
if(!suppressWarnings(require(groundhog))){remotes::install_github('CredibilityLab/groundhog')}
library("groundhog")

# Put all packages in and call groundhog
pkgs <- c(
    "aws.s3",
    "tidyverse"
    )

pkgs_all <- c(pkgs)

# Change out the date for today's date (unless you are running an old analysis)
groundhog.library(pkgs_all, "2023-11-27")


# Importing the data: 
full_data_widelong <- read.csv("~/Downloads/Dehumanization Project/full_data_widelong.csv")

# Necessary libraries
library(dplyr)
library(ggplot2)

# Exclude the last row with prompt descriptions for these descriptive analyses:
full_data_widelong <- full_data_widelong[-nrow(full_data_widelong), ]
view(full_data_widelong)
```


### Participant Demographics - 
```{r Number of Participants}

# Number of Participants
unique_participants <- full_data_widelong %>% distinct(Prolific_ID, .keep_all = TRUE) # Filtering unique participants based on Prolific_ID
num_participants <- nrow(unique_participants) # Count unique participants
print(paste("Number of Participants:", num_participants))

```
 
```{r Gender Distribution of Participants}

# Gender Distribution
gender_stats <- table(unique_participants$Gender)
print(gender_stats)

```

```{r Age Distribution of Participants}

age_stats <- summary(unique_participants$Age)
print(age_stats)
ggplot(unique_participants, aes(x=Age)) + 
  geom_histogram(binwidth=1, fill="blue", color="black") +
  scale_x_continuous(breaks=seq(10, 80, by=10), limits=c(10, 80)) +
  ylim(0, 5) +
  labs(title="Age Distribution of Unique Participants", x="Age", y="Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r Race Distribution of Participants}

# Race Distribution
race_stats <- table(unique_participants$Race)
print(race_stats)
ggplot(unique_participants, aes(x=Race, fill=Race)) +
  geom_bar() +
  labs(title="Race Distribution of Participants", x="Race", y="Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r Income Distribution of Participants}

# Income Distribution
income_ordered <- c("Less than $40,000", "$40,000-$79,999", "$80,000-$119,999", "$120,000-$199,999", "More than $200,000")
unique_participants$Income <- factor(unique_participants$Income, levels = income_ordered)
income_stats <- table(unique_participants$Income)
print(income_stats)
ggplot(unique_participants, aes(x=Income, fill=Income)) +
  geom_bar() +
  labs(title="Income Distribution of Participants", x="Income", y="Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r Conservatism Distribution of Participants}

# Conservatism Distribution
conservatism_ordered <- c("Extremely Liberal", "Liberal", "Somewhat Liberal", "Middle of the Road", "Somewhat Conservative", "Conservative", "Extremely Conservative")
unique_participants$Conservatism <- factor(unique_participants$Conservatism, levels = conservatism_ordered)
conservatism_stats <- table(unique_participants$Conservatism)
print(conservatism_stats)
ggplot(unique_participants, aes(x=Conservatism, fill=Conservatism)) +
  geom_bar() +
  labs(title="Conservatism Distribution of Participants", x="Conservatism", y="Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r Education Distribution of Participants}

# Education Distribution
education_ordered <- c("High school/GED", "Some college experience", "2-year college degree (A.A.)", "4-year college degree (BA/BS)", "Graduate or Professional Degree (MA/ MBA/ MS/ PhD)")
unique_participants$Education <- factor(unique_participants$Education, levels = education_ordered)
education_stats <- table(unique_participants$Education)
print(education_stats)
ggplot(unique_participants, aes(x=Education, fill=Education)) +
  geom_bar() +
  labs(title="Education Distribution of Participants", x="Education", y="Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


### Running a Binomial Test

#### In our study, we aim to determine whether participants exhibit a preference for selecting agents that express a dehumanizing reaction (DH) over those that express a non-dehumanizing reaction (NDH), beyond what would be expected by mere chance. To evaluate this, we have chosen to conduct a Binomial Test.

```{r Binomial Test }

# Loading the dataset
full_data_widelong <- read.csv("~/Downloads/Dehumanization Project/full_data_widelong.csv")

# Check unique values in 'choice' column to ensure it's binary
full_data_widelong$choice <- factor(full_data_widelong$choice)
unique(full_data_widelong$choice)

# Count the number of DH choices
num_DH_choices <- sum(as.character(full_data_widelong$choice) == "DH", na.rm = TRUE)
num_DH_choices <- as.integer(num_DH_choices)
total_choices <- sum(!is.na(full_data_widelong$choice))

# Perform the Binomial Test
binomial_test <- binom.test(x = num_DH_choices, n = total_choices, p = 0.5)
print(binomial_test)

# Interpreting the results of the Binomial Test:
# The p-value of < 2.2e-16 indicates that the choice of DH is significantly different from chance.

```


### Running a Mixed-effects Model

#### This new approach provides insights into the variability of choices between "DH" and "NDH" across participants, accounting for the fact that multiple choices come from the same participant.

```{r Nested Data - Mixed-effects Model}

install.packages("lme4")
install.packages("lmerTest")
library(lme4)
library(lmerTest) # For summaries including p-values

# Loading the dataset
experiment_data_long_test <- read.csv("~/Downloads/Dehumanization Project/experiment_data_long.csv")

# Preprocessing the data
experiment_data_long_test <- subset(experiment_data_long_test, !is.na(trial)) # Remove phone and gender rows
experiment_data_long_test <- subset(experiment_data_long_test, choice != 0) # Remove rows where 'choice' is 0
experiment_data_long_test$choice <- ifelse(experiment_data_long_test$rating == "DH", 1, 0) # Convert 'choice' from DH/NDH to 1/0

# Fit a mixed-effects logistic regression model. The (1 | Prolific_ID) adds a random effect for each participant.
model <- glmer(choice ~ 1 + (1 | Prolific_ID), family = binomial, data = experiment_data_long_test)

# View the summary of the model
summary(model)


# 1. Visual Summary: Individual differences in the choice patterns
library(ggplot2) # Load necessary library
experiment_data_long_test$choice <- as.numeric(experiment_data_long_test$rating == "DH") # Counting DH choices
proportions <- aggregate(choice ~ Prolific_ID, data = experiment_data_long_test, mean) # Proportion of DH choices
ggplot(proportions, aes(x = Prolific_ID, y = choice)) + # Plotting
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Proportion of DH Choices per Participant", x = "Participant ID", y = "Proportion of DH Choices")

# Interpretation of the Output:
  # AIC/BIC (Akaike and Bayesian Information Criterion): These values are useful for comparing different models fit to this data to see if they provide a better balance of goodness of fit and simplicity. If this is the only model you are considering, then the AIC and BIC give you a baseline for comparison if you decide to add more predictors or make other adjustments to your model.
  # Random Effects: Tell us much variability there is in the choices among different participants. For us, the random effect of Prolific_ID shows some level of variability across participants.
  # Fixed Effects: The fixed effect is the intercept; Tells us the log odds of choosing DH (versus NDH) when all other variables are held at zero.
  # The z-value and p-value (Pr(>|z|)) for the intercept test whether it is significantly different from zero. A significant intercept in a model with no other predictors suggests that there is an overall tendency towards one choice over the other in the population. So, since ours is negative and is statistically significant, this suggests that the overall tendency is towards choosing NDH over DH.


# 2. Visualize Random Effects: How participant-level intercepts vary around the overall intercept
library(lattice) # Load necessary library
ranef_plot <- dotplot(ranef(model, condVar = TRUE)) # Extract and plot random effects
print(ranef_plot)

# Interpretation of the Plot:
  # Fair amount of variability among participants, with some showing a much higher or lower tendency to choose DH compared to the average (the vertical line at x=0). The intercept for some participants is significantly different from zero, which reinforces the appropriateness of using a mixed-effects model for your data since it accounts for this individual variability.


# 3. Visualize the residuals of our mixed-effects model
plot(residuals(model), main="Residuals Plot")

# Interpretation of the Plot:
  # Clusters at two levels is expected in logistic regression. For many observations, the model's predictions are close to the actual values.
  # No obvious pattern to the residuals, suggesting the model's variance is constant across different levels of prediction (homoscedasticity).
  # A few residuals with higher absolute values. Possibly outliars or the model didn't fit very well?


# 4. Visualize the predicted probabilities of choosing DH for each participant.
experiment_data_long_test$predicted_prob <- predict(model, type = "response")
ggplot(experiment_data_long_test, aes(x = Prolific_ID, y = predicted_prob)) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Predicted Probabilities of DH Choice per Participant", 
       x = "Participant ID", y = "Predicted Probability")

# Interpretation of the Plot:
  # The y-axis shows the predicted probability that the participant will choose DH (0 is no chance, 1 is certainty)
  # The vertical spread of points indicates there is some variation among participants in their probability of choosing DH (i.e.) participants have different propensities for choosing DH. Our mixed-effects model accounts for the individual-level variation!
  # Most predicted probabilities are below 0.5, indicating a general tendency away from choosing DH among participants.



```















### H1 (Main Effect) Analysis (replace this with description of H1)

#### How does [main effect variable] influence [results]?

```{r H1}

## analysis and p-value of H1

## graph of H1

```

### Exploratory Analysis (replace this with description)

#### How does [exploratory variable] influence [results]?

```{r Exploratory}

## analysis and p-value

## graph
```



### Power Analysis 

```{r Power analysis}


set.seed(2532)

PowerModel = "" ##replace with main effect analysis

## use this line to extend the number of trials
PowerModelExt = extend(PowerModel, within = "participant_id+ratingType", n = 50)

## use this line to extend the number of participants
PowerModelExt = extend(PowerModelExt, along = "participant_id", n = 200)

## run sim
powerSim(PowerModelExt, nsim=1000)

# model the curve of this hypothetical experiment
pc <-  powerCurve(PowerModelExt, nsim = 1000, along = "participant_id") 

# plot and numbers
pc 
plot(pc)

```
